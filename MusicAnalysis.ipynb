{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import billboard\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getLyricsFromWikia(artist, title):\n",
    "    try:\n",
    "        BASE_URL = \"http://lyrics.wikia.com/wiki/Special:Search?search={}:{}\"\n",
    "        url = BASE_URL.format(artist.replace(\" \", \"+\"), title.replace(\" \", \"+\"))\n",
    "        page = requests.get(url)\n",
    "        soup = BeautifulSoup(page.text, 'html.parser')\n",
    "        resultBox = soup.find(\"li\", {'class', 'result'})\n",
    "        resultLink = resultBox.find(\"a\", {'class', 'result-link'}, href=True)\n",
    "        resultUrl = resultLink.get('href')\n",
    "        page = requests.get(resultUrl)\n",
    "        soup = BeautifulSoup(page.text, 'html.parser')\n",
    "        lyricBox = soup.find('div', {'class': 'lyricbox'})\n",
    "        for br in lyricBox.findAll('br'):\n",
    "            br.replace_with('\\n')\n",
    "        return lyricBox.text.strip()\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getBillboardCorpus(totalWeeks=1):\n",
    "    songIndex = 0\n",
    "    weekNum = 0\n",
    "    cut_off_list = [\" Featuring\", \" x \", \" X \", \" Duet With \", \" &\", \",\"]\n",
    "    music_collection = dict({})\n",
    "    chart = billboard.ChartData('hot-100')\n",
    "    while (weekNum < totalWeeks):\n",
    "        while (songIndex < len(chart.entries)):\n",
    "            song = chart[songIndex]\n",
    "            artist = song.artist\n",
    "            for cut_off in cut_off_list:\n",
    "                if cut_off in artist:\n",
    "                    artist = artist[:artist.find(cut_off)]\n",
    "            title = song.title\n",
    "            lyrics = None\n",
    "            if artist not in music_collection:\n",
    "                music_collection[artist] = {}\n",
    "            if title not in music_collection[artist]:\n",
    "                lyrics = getLyricsFromWikia(song.artist, title)\n",
    "                if lyrics is None:\n",
    "                    lyrics = getLyricsFromWikia(artist, title)\n",
    "                music_collection[artist][title] = lyrics\n",
    "                if lyrics is None:\n",
    "                    music_collection[artist][title] = \"\"\n",
    "                    print(song)\n",
    "            songIndex += 1\n",
    "        weekNum += 1\n",
    "        songIndex = 0\n",
    "        chart = billboard.ChartData('hot-100', chart.previousDate)\n",
    "    return music_collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getArtistCorpus(artist):\n",
    "    artistCorpus = {}\n",
    "    for album in getAlbums(artist):\n",
    "        artistCorpus[album[0]] = {}\n",
    "        for song in getSongs(album):\n",
    "            try:\n",
    "                page = requests.get(song[1])\n",
    "                soup = BeautifulSoup(page.content, 'html.parser')\n",
    "                lyricBox = soup.find('div', {'class': 'lyricbox'})\n",
    "                for br in lyricBox.findAll('br'):\n",
    "                    br.replace_with('\\n')\n",
    "                lyrics = lyricBox.text.strip()\n",
    "                artistCorpus[album[0]][song[0]] = lyrics\n",
    "            except:\n",
    "                continue\n",
    "    return artistCorpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getAlbums(artist):\n",
    "    BASE_URL = \"http://lyrics.wikia.com/wiki/{}\".format(artist)\n",
    "    page = requests.get(BASE_URL)\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "    headlines = soup.findAll(\"span\", {\"class\", \"mw-headline\"})\n",
    "    albums = []\n",
    "    for headline in headlines:\n",
    "        link = headline.find(\"a\")\n",
    "        if link is not None:\n",
    "            title = link[\"title\"]\n",
    "            albumTitle = title[title.find(\":\")+1:title.find(\" (\")]\n",
    "            albums.append( (albumTitle, \"https://lyrics.wikia.com{0}\".format(link[\"href\"])))\n",
    "    return albums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getSongs(album):\n",
    "    link = album[1]\n",
    "    page = requests.get(link)\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "    content = soup.find(\"div\", {\"class\":\"mw-content-text\"})\n",
    "    songs = []\n",
    "    if content is not None:\n",
    "        trackListBox = content.find(\"ol\")\n",
    "        songItems = trackListBox.findAll(\"li\")\n",
    "        for songItem in songItems:\n",
    "            songLink = songItem.find(\"a\")\n",
    "            title = songLink.string\n",
    "            url = \"http://lyrics.wikia.com{0}\".format(songLink[\"href\"])\n",
    "            songs.append((title, url))\n",
    "    return songs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def corpusToString(corpus):\n",
    "    lyrics = \"\"\n",
    "    for album in corpus.keys():\n",
    "        for song in corpus[album]:\n",
    "            lyrics += corpus[album][song]\n",
    "    return lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save(corpus, nameOfArtist):\n",
    "    with open(\"{}Text.txt\".format(nameOfArtist), \"w\") as file:\n",
    "        file.write(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def retrieve(nameOfArtist):\n",
    "    with open(\"{}Text.txt\".format(nameOfArtist), \"r\") as file:\n",
    "        lyrics = file.read()\n",
    "    return lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process(lyrics):\n",
    "    tokens = word_tokenize(lyrics)\n",
    "    text = nltk.Text(tokens)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def keyWords(corpus):\n",
    "    fdist = nltk.FreqDist(corpus);\n",
    "    keyWords = [keyWord for keyWord in set(corpus) if fdist[keyWord] > 25 and len(keyWord) > 7] #targets frequent words and filters out articles\n",
    "    return keyWords"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
